import os
import cv2
import streamlit as st
import asyncio
import boto3
import time
from concurrent.futures import ThreadPoolExecutor
from translations import init_language, set_language, translations
from utils import (
    get_image_hash,
    hamming_distance,
    resize_and_pad_image,
    crop_image,
    apply_color_jitter,
    add_border,
    invoke_sagemaker_endpoint,
)

st.set_page_config(page_title="Realtime Detect Video", page_icon="ğŸ“¹")

# ì–¸ì–´ ì´ˆê¸°í™” ë° ì„ íƒ
init_language()
set_language()
current_language = st.session_state["language"]
text = translations[current_language]["video"]


# ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
async def async_invoke_sagemaker(frame_idx, processed_img, loop, executor):
    result = await loop.run_in_executor(
        executor,
        invoke_sagemaker_endpoint,
        "diecasting-model-T7-endpoint",
        processed_img,
    )
    return frame_idx, result


async def realtime_process_video_async(video_path, tolerance=5, frame_interval=2):
    cap = cv2.VideoCapture(video_path)
    prev_hash = None

    frame_index = 0
    part_number = 1
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    current_part_images = []  # í˜„ì¬ ë¶€í’ˆ ì´ë¯¸ì§€ ì €ì¥
    ng_detect = {}
    ok_detect = {}

    # ThreadPoolExecutor ìƒì„±
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor()

    # ë³‘ë ¬ ì‘ì—… ê´€ë¦¬ìš© Semaphore
    semaphore = asyncio.Semaphore(10)  # ìµœëŒ€ ë™ì‹œ Task ìˆ˜ ì œí•œ

    # ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì¶œë ¥ìš© ì»¨í…Œì´ë„ˆ
    realtime_container = st.empty()

    async def process_frame(frame, frame_idx):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        nonlocal prev_hash, current_part_images, part_number

        current_hash = get_image_hash(frame)

        # ì¤‘ë³µ í”„ë ˆì„ ì œê±°
        if prev_hash is None or (
            tolerance < hamming_distance(prev_hash, current_hash) < 40
        ):
            prev_hash = current_hash

            # opencv ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_img = resize_and_pad_image(
                crop_image(apply_color_jitter(frame, brightness=1.0, contrast=1.0), 1.0)
            )

            # ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
            frame_idx, result = await async_invoke_sagemaker(
                frame_idx, processed_img, loop, executor
            )

            label = "OK" if result == 1 else "NG"
            label_color = (0, 255, 0) if result == 1 else (0, 0, 255)
            bordered_frame = add_border(frame, label_color)

            # ì‘ë‹µ ì €ì¥
            current_part_images.append((frame_idx, bordered_frame, label))
            # í”„ë ˆì„ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            current_part_images.sort(key=lambda x: x[0])

            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶œë ¥
            with realtime_container.container():
                st.markdown(f"### No. {part_number}")
                cols = st.columns(5)
                for idx, (_, img, lbl) in enumerate(current_part_images):
                    cols[idx].image(
                        img,
                        channels="BGR",
                        caption=f"Channel {idx + 1}: {lbl}",
                    )

            # ë¶€í’ˆ ìƒíƒœ í™•ì¸ (5ê°œì˜ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ì±„ì›Œì§€ë©´)
            if len(current_part_images) == 5:
                part_status = (
                    "OK"
                    if "NG" not in [lbl for _, _, lbl in current_part_images]
                    else "NG"
                )

                # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥
                if part_status == "NG":
                    ng_detect[part_number] = [
                        (img, lbl) for _, img, lbl in current_part_images
                    ]
                else:
                    ok_detect[part_number] = [
                        (img, lbl) for _, img, lbl in current_part_images
                    ]

                # ë¶€í’ˆ ìƒíƒœ ì¶œë ¥
                with realtime_container.container():
                    st.markdown(f"### No. {part_number} - {part_status}")
                    cols = st.columns(5)
                    for idx, (_, img, lbl) in enumerate(current_part_images):
                        cols[idx].image(
                            img,
                            channels="BGR",
                            caption=f"Channel {idx + 1}: {lbl}",
                        )

                # ì´ˆê¸°í™”
                current_part_images = []
                realtime_container.empty()
                part_number += 1

    # ì œí•œëœ í”„ë ˆì„ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ëª© ë°©ì§€)
    async def limited_process_frame(frame, frame_idx):
        async with semaphore:
            return await process_frame(frame, frame_idx)

    # ì‹¤í–‰ í•¨ìˆ˜
    tasks = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # ì˜ìƒ ëì— ë„ë‹¬í•œ ê²½ìš°

        # í”„ë ˆì„ ìƒ˜í”Œë§
        if frame_index % frame_interval == 0:
            tasks.append(limited_process_frame(frame, frame_index))

        frame_index += 1

    await asyncio.gather(*tasks)

    cap.release()
    realtime_container.empty()
    return ng_detect, ok_detect


@st.cache_data
def get_cached_images(detect, part_number):
    return detect[part_number]


def show_result_details(detect, status):
    container = st.container()
    with container:
        st.subheader(f"{status} {text["detailed_image"]}")
        selected_part = st.selectbox(
            f"{text["select_img_box"]} : {status}",
            options=list(detect.keys()),
            key=f"select_{status}",
        )

    if selected_part:
        st.subheader(f"No. {selected_part}")
        images = get_cached_images(detect, selected_part)
        cols = st.columns(5)
        for idx, (image, label) in enumerate(images):
            cols[idx % 5].image(
                image,
                channels="BGR",
                caption=f"Part {selected_part} - Channel {idx + 1}: {label}",
            )


def upload_results_to_s3(ng_detect, ok_detect):
    s3 = boto3.client("s3")

    upload_time = time.strftime("%Y%m%d_%H%M%S")


# ë©”ì¸ í•¨ìˆ˜
def realtime_video_inference():
    st.title(text["title"])

    uploaded_file = st.file_uploader(text["upload"], type=["mp4", "mov", "avi"])

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "upload_time" not in st.session_state:
        st.session_state.upload_time = None  # ì—…ë¡œë“œ ì‹œê°„ ì €ì¥
    if "analysis_done" not in st.session_state:
        st.session_state.analysis_done = False  # ë¶„ì„ ìƒíƒœ ì¶”ì 

    if uploaded_file is not None:
        current_upload_time = time.strftime("%Y%m%d_%H%M%S")  # í˜„ì¬ ì—…ë¡œë“œ ì‹œê°„
        # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì´ë²¤íŠ¸ ì²˜ë¦¬
        if st.session_state.upload_time != current_upload_time:
            # ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.upload_time = current_upload_time
            st.session_state.analysis_done = False

        temp_video_path = f"temp_{uploaded_file.name}"
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(
            f"{text["upload_success"]} : {uploaded_file.name} ({st.session_state['upload_time']})"
        )
        st.video(temp_video_path, autoplay=True, muted=True)

        if not st.session_state.analysis_done:
            with st.spinner(text["processing"]):
                (
                    ng_detect,
                    ok_detect,
                ) = asyncio.run(
                    realtime_process_video_async(temp_video_path, tolerance=5)
                )
                st.session_state.analysis_done = True

        # ê²°ê³¼ ì¶œë ¥
        st.subheader(text["summary"])
        if len(ng_detect.keys()) > 0:
            if current_language == "en":
                st.error(
                    f"{text['total']} {len(ng_detect.keys())} NG {text['parts']}: {list(ng_detect.keys())}"
                )
            elif current_language == "kr":
                st.error(
                    f"{text['total']} {len(ng_detect.keys())}ê°œì˜ NG {text['parts']}: {list(ng_detect.keys())}"
                )
        if len(ok_detect.keys()) > 0:
            if current_language == "en":
                st.success(
                    f"{text['total']} {len(ok_detect.keys())} OK {text['parts']}: {list(ok_detect.keys())}"
                )
            elif current_language == "kr":
                st.success(
                    f"{text['total']} {len(ok_detect.keys())}ê°œì˜ OK {text['parts']}: {list(ok_detect.keys())}"
                )

        @st.fragment
        def show_ng_section():
            if len(ng_detect) > 0:
                show_result_details(ng_detect, "NG")

        @st.fragment
        def show_ok_section():
            if len(ok_detect) > 0:
                show_result_details(ok_detect, "OK")

        show_ng_section()
        show_ok_section()

        # ì‚­ì œ: ë¶„ì„ì´ ëë‚œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)


if __name__ == "__main__":
    realtime_video_inference()
