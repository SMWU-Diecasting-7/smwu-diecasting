import os
import cv2
import streamlit as st
import asyncio
import numpy as np
import time
from concurrent.futures import ThreadPoolExecutor
from utils import (
    get_image_hash,
    hamming_distance,
    resize_and_pad_image,
    crop_image,
    apply_color_jitter,
    add_border,
    invoke_sagemaker_endpoint,
)
import json
import boto3

st.set_page_config(page_title="Realtime Detect Video", page_icon="ğŸ“¹")


# ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
async def async_invoke_sagemaker(frame_idx, processed_img, loop, executor):
    result = await loop.run_in_executor(
        executor,
        invoke_sagemaker_endpoint,
        "diecasting-model-T7-endpoint",
        processed_img,
    )
    return frame_idx, result


async def realtime_process_video_async(video_path, tolerance=5, frame_interval=2):
    cap = cv2.VideoCapture(video_path)
    prev_hash = None

    frame_index = 0
    part_number = 1
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    current_part_images = []  # í˜„ì¬ ë¶€í’ˆ ì´ë¯¸ì§€ ì €ì¥
    ng_detect = {}
    ok_detect = {}

    # ThreadPoolExecutor ìƒì„±
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor()

    # ë³‘ë ¬ ì‘ì—… ê´€ë¦¬ìš© Semaphore
    semaphore = asyncio.Semaphore(10)  # ìµœëŒ€ ë™ì‹œ Task ìˆ˜ ì œí•œ

    # ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì¶œë ¥ìš© ì»¨í…Œì´ë„ˆ
    realtime_container = st.empty()

    async def process_frame(frame, frame_idx):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        nonlocal prev_hash, current_part_images, part_number

        current_hash = get_image_hash(frame)

        # ì¤‘ë³µ í”„ë ˆì„ ì œê±°
        if prev_hash is None or (
            tolerance < hamming_distance(prev_hash, current_hash) < 40
        ):
            prev_hash = current_hash

            # opencv ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_img = resize_and_pad_image(
                crop_image(apply_color_jitter(frame, brightness=1.0, contrast=1.0), 1.0)
            )

            # ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
            frame_idx, result = await async_invoke_sagemaker(
                frame_idx, processed_img, loop, executor
            )

            label = "OK" if result == 1 else "NG"
            label_color = (0, 255, 0) if result == 1 else (0, 0, 255)
            bordered_frame = add_border(frame, label_color)

            # ì‘ë‹µ ì €ì¥
            current_part_images.append((frame_idx, bordered_frame, label))
            # í”„ë ˆì„ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            current_part_images.sort(key=lambda x: x[0])

            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶œë ¥
            with realtime_container.container():
                st.markdown(f"### No. {part_number}")
                cols = st.columns(5)
                for idx, (_, img, lbl) in enumerate(current_part_images):
                    cols[idx].image(
                        img,
                        channels="BGR",
                        caption=f"Channel {idx + 1}: {lbl}",
                    )

            # ë¶€í’ˆ ìƒíƒœ í™•ì¸ (5ê°œì˜ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ì±„ì›Œì§€ë©´)
            if len(current_part_images) == 5:
                part_status = (
                    "OK"
                    if "NG" not in [lbl for _, _, lbl in current_part_images]
                    else "NG"
                )

                # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥
                if part_status == "NG":
                    ng_detect[part_number] = [
                        img for _, img, lbl in current_part_images
                    ]
                else:
                    ok_detect[part_number] = [
                        img for _, img, lbl in current_part_images
                    ]

                # ë¶€í’ˆ ìƒíƒœ ì¶œë ¥
                with realtime_container.container():
                    st.markdown(f"### No. {part_number} - {part_status}")
                    cols = st.columns(5)
                    for idx, (_, img, lbl) in enumerate(current_part_images):
                        cols[idx].image(
                            img,
                            channels="BGR",
                            caption=f"Channel {idx + 1}: {lbl}",
                        )

                # ì´ˆê¸°í™”
                current_part_images = []
                realtime_container.empty()
                part_number += 1

    # ì œí•œëœ í”„ë ˆì„ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ëª© ë°©ì§€)
    async def limited_process_frame(frame, frame_idx):
        async with semaphore:
            return await process_frame(frame, frame_idx)

    # ì‹¤í–‰ í•¨ìˆ˜
    tasks = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # ì˜ìƒ ëì— ë„ë‹¬í•œ ê²½ìš°

        # í”„ë ˆì„ ìƒ˜í”Œë§
        if frame_index % frame_interval == 0:
            tasks.append(limited_process_frame(frame, frame_index))

        frame_index += 1

    await asyncio.gather(*tasks)

    cap.release()
    realtime_container.empty()
    return ng_detect, ok_detect


@st.cache_data
def get_cached_images(detect, part_number):
    return detect[part_number]


def show_result_details(detect, status):
    container = st.container()
    with container:
        st.subheader(f"{status} Detailed Images")
        selected_part = st.selectbox(
            f"Select Part to View {status} Images",
            options=list(detect.keys()),
            key=f"select_{status}",
        )

    if selected_part:
        st.write(f"Showing {status} Images for Part {selected_part}")
        images = get_cached_images(detect, selected_part)
        cols = st.columns(5)
        for idx, image in enumerate(images):
            cols[idx % 5].image(
                image,
                channels="BGR",
                caption=f"Part {selected_part} - Channel {idx + 1}",
            )

# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
def get_s3_client():
    return boto3.client(
        "s3",
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
        region_name=os.getenv("AWS_REGION"),
    )

# S3ì— ê²°ê³¼ ì €ì¥
def upload_results_to_s3(bucket_name, key, data):
    s3 = get_s3_client()
    s3.put_object(
        Bucket=bucket_name,
        Key=key,
        Body=json.dumps(data),
        ContentType="application/json",
    )

# S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
def upload_image_to_s3(bucket_name, key, image):
    _, img_encoded = cv2.imencode(".jpg", image)
    s3 = get_s3_client()
    s3.put_object(
        Bucket=bucket_name,
        Key=key,
        Body=img_encoded.tobytes(),
        ContentType="image/jpeg",
    )
    return f"s3://{bucket_name}/{key}"

# S3ì—ì„œ JSON ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def fetch_results_from_s3(bucket_name, prefix):
    s3 = get_s3_client()
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

    results = []
    if "Contents" in response:
        for obj in response["Contents"]:
            key = obj["Key"]
            if key.endswith(".json"):
                json_data = s3.get_object(Bucket=bucket_name, Key=key)["Body"].read()
                results.append(json.loads(json_data))
    return results

# ê²°ê³¼ë¥¼ ë¼ë²¨ë³„ë¡œ ì €ì¥
def save_results_with_images_to_s3(
    bucket_name, video_name, ng_images, ok_images
):
    result_data = {"video_name": video_name, "ng_parts": [], "ok_parts": []}

    for idx, image in enumerate(ng_images):
        key = f"results/{video_name}/NG_part_{idx + 1}.jpg"
        image_url = upload_image_to_s3(bucket_name, key, image)
        result_data["ng_parts"].append({"part_number": idx + 1, "image_url": image_url})

    for idx, image in enumerate(ok_images):
        key = f"results/{video_name}/OK_part_{idx + 1}.jpg"
        image_url = upload_image_to_s3(bucket_name, key, image)
        result_data["ok_parts"].append({"part_number": idx + 1, "image_url": image_url})

    # JSON ë°ì´í„° ì €ì¥
    json_key = f"results/{video_name}/results.json"
    upload_results_to_s3(bucket_name, json_key, result_data)

# ë©”ì¸ í•¨ìˆ˜
def realtime_video_inference():
    st.title("Real-time NG/OK Detection with Video")

    # S3 ë²„í‚· ì •ë³´
    bucket_name = "cv-7-video"
    results_prefix = "results/"

    uploaded_file = st.file_uploader("Choose a video file", type=["mp4", "mov", "avi"])

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "upload_time" not in st.session_state:
        st.session_state.upload_time = None  # ì—…ë¡œë“œ ì‹œê°„ ì €ì¥
    if "analysis_done" not in st.session_state:
        st.session_state.analysis_done = False  # ë¶„ì„ ìƒíƒœ ì¶”ì 

    if uploaded_file is not None:
        current_upload_time = time.strftime("%Y%m%d_%H%M%S")  # í˜„ì¬ ì—…ë¡œë“œ ì‹œê°„
        # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì´ë²¤íŠ¸ ì²˜ë¦¬
        if st.session_state.upload_time != current_upload_time:
            # ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.upload_time = current_upload_time
            st.session_state.analysis_done = False

        temp_video_path = f"temp_{uploaded_file.name}"
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(
            f"Complete Upload File : {uploaded_file.name} ({st.session_state['upload_time']})"
        )
        st.video(temp_video_path, autoplay=True, muted=True)

        if not st.session_state.analysis_done:
            with st.spinner("Anlayzing video"):
                ng_detect, ok_detect = asyncio.run(
                    realtime_process_video_async(temp_video_path, tolerance=5)
                )
                st.session_state.analysis_done = True

                # ê²°ê³¼ë¥¼ S3ì— ì €ì¥
                result_data = {
                    "video_name": uploaded_file.name,
                    "ng_parts": list(ng_detect.keys()),
                    "ok_parts": list(ok_detect.keys()),
                }
                result_key = f"{results_prefix}{uploaded_file.name}.json"
                upload_results_to_s3(bucket_name, result_key, result_data)
                st.success(f"Results saved to S3: {result_key}")

        # ê²°ê³¼ ì¶œë ¥
        st.subheader("Final Result Summary")
        st.error(f"Total {len(ng_detect.keys())} NG Parts: {list(ng_detect.keys())}")
        st.success(f"Total {len(ok_detect.keys())} OK Parts: {list(ok_detect.keys())}")

        @st.fragment
        def show_ng_section():
            if len(ng_detect) > 0:
                show_result_details(ng_detect, "NG")

        @st.fragment
        def show_ok_section():
            if len(ok_detect) > 0:
                show_result_details(ok_detect, "OK")

        show_ng_section()
        show_ok_section()

        # ì‚­ì œ: ë¶„ì„ì´ ëë‚œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)


if __name__ == "__main__":
    realtime_video_inference()
